{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69965432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6b00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train1.csv')\n",
    "test_df=pd.read_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9640cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_dict = {\n",
    "    \"P1_B2004\": \"hx_press_sp\",\n",
    "    \"P1_B2016\": \"power_press_demand\",\n",
    "    \"P1_B3004\": \"rtn_level_sp\",\n",
    "    \"P1_B3005\": \"rtn_flow_sp\",\n",
    "    \"P1_B4002\": \"hx_temp_sp\",\n",
    "    \"P1_B4005\": \"temp_pid_out\",\n",
    "    \"P1_B400B\": \"heat_outflow_sp\",\n",
    "    \"P1_B4022\": \"power_temp_demand\",\n",
    "\n",
    "    \"P1_FCV01D\": \"fcv01_cmd\",\n",
    "    \"P1_FCV01Z\": \"fcv01_pos\",\n",
    "    \"P1_FCV02D\": \"fcv02_cmd\",\n",
    "    \"P1_FCV02Z\": \"fcv02_pos\",\n",
    "    \"P1_FCV03D\": \"fcv03_cmd\",\n",
    "    \"P1_FCV03Z\": \"fcv03_pos\",\n",
    "\n",
    "    \"P1_FT01\": \"rtn_flow_raw\",\n",
    "    \"P1_FT01Z\": \"rtn_flow\",\n",
    "    \"P1_FT02\": \"heat_flow_raw\",\n",
    "    \"P1_FT02Z\": \"heat_flow\",\n",
    "    \"P1_FT03\": \"rtn_flow2_raw\",\n",
    "    \"P1_FT03Z\": \"rtn_flow2\",\n",
    "\n",
    "    \"P1_LCV01D\": \"lcv01_cmd\",\n",
    "    \"P1_LCV01Z\": \"lcv01_pos\",\n",
    "\n",
    "    \"P1_LIT01\": \"rtn_level\",\n",
    "\n",
    "    \"P1_PCV01D\": \"pcv01_cmd\",\n",
    "    \"P1_PCV01Z\": \"pcv01_pos\",\n",
    "    \"P1_PCV02D\": \"pcv02_cmd\",\n",
    "    \"P1_PCV02Z\": \"pcv02_pos\",\n",
    "\n",
    "    \"P1_PIT01\": \"hx_press\",\n",
    "    \"P1_PIT01_HH\": \"hx_press_high\",\n",
    "    \"P1_PIT02\": \"pump_supply_press\",\n",
    "\n",
    "    \"P1_PP01AD\": \"pump1A_cmd\",\n",
    "    \"P1_PP01AR\": \"pump1A_run\",\n",
    "    \"P1_PP01BD\": \"pump1B_cmd\",\n",
    "    \"P1_PP01BR\": \"pump1B_run\",\n",
    "    \"P1_PP02D\": \"pump2_cmd\",\n",
    "    \"P1_PP02R\": \"pump2_run\",\n",
    "\n",
    "    \"P1_PP04\": \"cooler_out\",\n",
    "    \"P1_PP04SP\": \"cooler_temp_sp\",\n",
    "\n",
    "    \"P1_SOL01D\": \"sol_supply_cmd\",\n",
    "    \"P1_SOL03D\": \"sol_drain_cmd\",\n",
    "\n",
    "    \"P1_STSP\": \"boiler_run_cmd\",\n",
    "\n",
    "    \"P1_TIT01\": \"hx_temp\",\n",
    "    \"P1_TIT02\": \"heat_tank_temp\",\n",
    "    \"P1_TIT03\": \"main_tank_temp\"\n",
    "}\n",
    "train_df.rename(columns=p1_dict, inplace=True)\n",
    "test_df.rename(columns=p1_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8ddf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 원본 코드\\ndf['fcv03_diff'] = abs(df['fcv03_pos'] - df['fcv03_cmd'])\\ndf['fcv03_cng'] = abs(df['fcv03_cmd'].diff().fillna(0))\\ndf['level_diff'] = df['rtn_level'].diff().fillna(0)\\ndf['level_diff_abs']=abs(df['level_diff'])\\ndf['flow_balance'] = df['rtn_flow'] - df['rtn_flow2']\\ndf['flow_balance_abs'] = abs(df['flow_balance'])\\ndf['phys_diff'] = df['level_diff'] - df['flow_balance']\\ndf['phys_diff_abs'] = abs(df['phys_diff'])\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' 원본 코드\n",
    "df['fcv03_diff'] = abs(df['fcv03_pos'] - df['fcv03_cmd'])\n",
    "df['fcv03_cng'] = abs(df['fcv03_cmd'].diff().fillna(0))\n",
    "df['level_diff'] = df['rtn_level'].diff().fillna(0)\n",
    "df['level_diff_abs']=abs(df['level_diff'])\n",
    "df['flow_balance'] = df['rtn_flow'] - df['rtn_flow2']\n",
    "df['flow_balance_abs'] = abs(df['flow_balance'])\n",
    "df['phys_diff'] = df['level_diff'] - df['flow_balance']\n",
    "df['phys_diff_abs'] = abs(df['phys_diff'])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726f7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_custom_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) 밸브 명령-위치 차이\n",
    "    df['fcv03_diff'] = (df['fcv03_pos'] - df['fcv03_cmd']).abs()\n",
    "\n",
    "    # 2) 밸브 명령 변화량\n",
    "    df['fcv03_cng'] = df['fcv03_cmd'].diff().fillna(0).abs()\n",
    "\n",
    "    # 3) 수위 변화량\n",
    "    df['level_diff'] = df['rtn_level'].diff().fillna(0)\n",
    "    df['level_diff_abs'] = df['level_diff'].abs()\n",
    "\n",
    "    # 4) 유량 균형\n",
    "    df['flow_balance'] = df['rtn_flow'] - df['rtn_flow2']\n",
    "    df['flow_balance_abs'] = df['flow_balance'].abs()\n",
    "\n",
    "    # 5) 물리 기반 차이값 (수위 변화 vs 유량 변화)\n",
    "    df['phys_diff'] = df['level_diff'] - df['flow_balance']\n",
    "    df['phys_diff_abs'] = df['phys_diff'].abs()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aad916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_custom_features(train_df)\n",
    "test_df  = add_custom_features(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4080c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "        'phys_diff_abs',\n",
    "        'flow_balance_abs',\n",
    "        'level_diff_abs',\n",
    "        'fcv03_cng',\n",
    "        'fcv03_diff',\n",
    "        'rtn_level',\n",
    "        'rtn_flow',\n",
    "        'rtn_flow2',\n",
    "        'fcv03_cmd',\n",
    "        'fcv03_pos',\n",
    "        'hx_press',\n",
    "        'attack'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde2a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df[feature_cols]\n",
    "test_df=test_df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950d6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols2 = [\n",
    "        'phys_diff_abs',\n",
    "        'flow_balance_abs',\n",
    "        'level_diff_abs',\n",
    "        'fcv03_cng',\n",
    "        'fcv03_diff',\n",
    "        'rtn_level',\n",
    "        'rtn_flow',\n",
    "        'rtn_flow2',\n",
    "        'fcv03_cmd',\n",
    "        'fcv03_pos',\n",
    "        'hx_press'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65fa8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[feature_cols2]\n",
    "y_train = train_df[\"attack\"]    # all zero\n",
    "\n",
    "X_test = test_df[feature_cols2]\n",
    "y_test = test_df[\"attack\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d59db3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7ece6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=600, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=600, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=600, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    scale_pos_weight=20,   # attack이 매우 적기 때문에 가중치 필요\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8be7aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42572     0]\n",
      " [  629     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     42572\n",
      "           1       0.00      0.00      0.00       629\n",
      "\n",
      "    accuracy                           0.99     43201\n",
      "   macro avg       0.49      0.50      0.50     43201\n",
      "weighted avg       0.97      0.99      0.98     43201\n",
      "\n",
      "AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bora0126\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\bora0126\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\bora0126\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "y_prob = model.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "threshold = 0.4\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278a6a6",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b9f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42446   126]\n",
      " [  322   307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     42572\n",
      "           1       0.71      0.49      0.58       629\n",
      "\n",
      "    accuracy                           0.99     43201\n",
      "   macro avg       0.85      0.74      0.79     43201\n",
      "weighted avg       0.99      0.99      0.99     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "feature_cols = [\n",
    "    'phys_diff_abs', 'flow_balance_abs', 'level_diff_abs',\n",
    "    'fcv03_cng', 'fcv03_diff', \n",
    "    'rtn_level', 'rtn_flow', 'rtn_flow2',\n",
    "    'fcv03_cmd', 'fcv03_pos', 'hx_press'\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "X_test  = test_df[feature_cols]\n",
    "y_test  = test_df['attack']   # 0/1 (test에는 공격 있음)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Isolation Forest (정상만 학습)\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=0.01, \n",
    "    random_state=42\n",
    ")\n",
    "iso.fit(X_train_scaled)\n",
    "\n",
    "# 예측: 정상=1, 이상=-1 로 나옴\n",
    "y_pred_iso = iso.predict(X_test_scaled)\n",
    "\n",
    "# -1 → 공격(1), 1 → 정상(0) 으로 매핑\n",
    "y_pred_attack = (y_pred_iso == -1).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_attack))\n",
    "print(classification_report(y_test, y_pred_attack))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc1b228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003 0.30842607313195547\n",
      "0.005 0.3863275039745628\n",
      "0.01 0.48807631160572335\n",
      "0.015 0.5580286168521462\n",
      "0.02 0.5977742448330684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "cont_list = [0.003, 0.005, 0.01, 0.015, 0.02]\n",
    "\n",
    "for c in cont_list:\n",
    "    iso = IsolationForest(\n",
    "        n_estimators=300,\n",
    "        contamination=c,\n",
    "        random_state=42\n",
    "    )\n",
    "    iso.fit(X_train_scaled)\n",
    "    \n",
    "    y_pred = (iso.predict(X_test_scaled) == -1).astype(int)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    print(c, rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45b7e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=50,\n",
    "    novelty=True  # test에서 예측 허용\n",
    ")\n",
    "lof.fit(X_train_scaled)\n",
    "\n",
    "y_pred = (lof.predict(X_test_scaled) == -1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c67d784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31099 11473]\n",
      " [  306   323]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.73      0.84     42572\n",
      "           1       0.03      0.51      0.05       629\n",
      "\n",
      "    accuracy                           0.73     43201\n",
      "   macro avg       0.51      0.62      0.45     43201\n",
      "weighted avg       0.98      0.73      0.83     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d89a8cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42322   250]\n",
      " [  253   376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     42572\n",
      "           1       0.60      0.60      0.60       629\n",
      "\n",
      "    accuracy                           0.99     43201\n",
      "   macro avg       0.80      0.80      0.80     43201\n",
      "weighted avg       0.99      0.99      0.99     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "feature_cols = [\n",
    "    'phys_diff_abs', 'flow_balance_abs', 'level_diff_abs',\n",
    "    'fcv03_cng', 'fcv03_diff', \n",
    "    'rtn_level', 'rtn_flow', 'rtn_flow2',\n",
    "    'fcv03_cmd', 'fcv03_pos', 'hx_press'\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "X_test  = test_df[feature_cols]\n",
    "y_test  = test_df['attack']   # 0/1 (test에는 공격 있음)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Isolation Forest (정상만 학습)\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=0.02,   \n",
    "    random_state=42\n",
    ")\n",
    "iso.fit(X_train_scaled)\n",
    "\n",
    "# 예측: 정상=1, 이상=-1 로 나옴\n",
    "y_pred_iso = iso.predict(X_test_scaled)\n",
    "\n",
    "# -1 → 공격(1), 1 → 정상(0) 으로 매핑\n",
    "y_pred_attack = (y_pred_iso == -1).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_attack))\n",
    "print(classification_report(y_test, y_pred_attack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f616ce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003 0.30842607313195547\n",
      "0.005 0.3863275039745628\n",
      "0.07 0.6677265500794912\n",
      "0.01 0.48807631160572335\n",
      "0.015 0.5580286168521462\n",
      "0.02 0.5977742448330684\n",
      "0.025 0.6200317965023847\n",
      "0.03 0.6327503974562798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "cont_list = [0.003, 0.005,0.07, 0.01, 0.015, 0.02,0.025,0.03]\n",
    "\n",
    "for c in cont_list:\n",
    "    iso = IsolationForest(\n",
    "        n_estimators=300,\n",
    "        contamination=c,\n",
    "        random_state=42\n",
    "    )\n",
    "    iso.fit(X_train_scaled)\n",
    "    \n",
    "    y_pred = (iso.predict(X_test_scaled) == -1).astype(int)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    print(c, rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96d77b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41917   655]\n",
      " [  209   420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42572\n",
      "           1       0.39      0.67      0.49       629\n",
      "\n",
      "    accuracy                           0.98     43201\n",
      "   macro avg       0.69      0.83      0.74     43201\n",
      "weighted avg       0.99      0.98      0.98     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "feature_cols = [\n",
    "    'phys_diff_abs', 'flow_balance_abs', 'level_diff_abs',\n",
    "    'fcv03_cng', 'fcv03_diff', \n",
    "    'rtn_level', 'rtn_flow', 'rtn_flow2',\n",
    "    'fcv03_cmd', 'fcv03_pos', 'hx_press'\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "X_test  = test_df[feature_cols]\n",
    "y_test  = test_df['attack']   # 0/1 (test에는 공격 있음)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Isolation Forest (정상만 학습)\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=0.07,   \n",
    "    random_state=42\n",
    ")\n",
    "iso.fit(X_train_scaled)\n",
    "\n",
    "# 예측: 정상=1, 이상=-1 로 나옴\n",
    "y_pred_iso = iso.predict(X_test_scaled)\n",
    "\n",
    "# -1 → 공격(1), 1 → 정상(0) 으로 매핑\n",
    "y_pred_attack = (y_pred_iso == -1).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_attack))\n",
    "print(classification_report(y_test, y_pred_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277af5c4",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e89ffe",
   "metadata": {},
   "source": [
    "- 피쳐를 망가뜨리면 얼마나 떨어지냐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266b358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcv03_pos        importance=0.0178 ± 0.0015\n",
      "fcv03_cmd        importance=0.0152 ± 0.0019\n",
      "rtn_level        importance=0.0095 ± 0.0017\n",
      "fcv03_cng        importance=0.0091 ± 0.0025\n",
      "rtn_flow2        importance=0.0069 ± 0.0015\n",
      "fcv03_diff       importance=0.0051 ± 0.0020\n",
      "level_diff_abs   importance=0.0001 ± 0.0027\n",
      "rtn_flow         importance=-0.0052 ± 0.0026\n",
      "hx_press         importance=-0.0171 ± 0.0024\n",
      "flow_balance_abs  importance=-0.0355 ± 0.0020\n",
      "phys_diff_abs    importance=-0.0444 ± 0.0020\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def iso_attack_predict(model, X):\n",
    "    y_pred = model.predict(X)              # 1 / -1\n",
    "    return (y_pred == -1).astype(int)      # 0 / 1\n",
    "\n",
    "def f1_scorer(estimator, X, y):\n",
    "    yhat = iso_attack_predict(estimator, X)\n",
    "    return f1_score(y, yhat)\n",
    "\n",
    "result = permutation_importance(\n",
    "    iso,\n",
    "    X_test_scaled,\n",
    "    y_test,\n",
    "    scoring=f1_scorer,\n",
    "    n_repeats=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "importances = result.importances_mean\n",
    "stds = result.importances_std\n",
    "\n",
    "# 중요도 큰 순서 출력\n",
    "idx = np.argsort(importances)[::-1]\n",
    "for i in idx:\n",
    "    print(f\"{feature_cols[i]:15s}  importance={importances[i]:.4f} ± {stds[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38f46e",
   "metadata": {},
   "source": [
    "- tree explainer - feature의 중요도 분석/의존도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9c3d498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bora0126\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level_diff_abs 0.25256525697720106\n",
      "rtn_level 0.24161925839465773\n",
      "rtn_flow2 0.23849502652698307\n",
      "fcv03_cng 0.1873990931311346\n",
      "hx_press 0.1837523392815218\n",
      "fcv03_diff 0.1834999466632229\n",
      "phys_diff_abs 0.16562202575707138\n",
      "flow_balance_abs 0.14873116377869436\n",
      "rtn_flow 0.147463197499367\n",
      "fcv03_cmd 0.13134869544749303\n",
      "fcv03_pos 0.10284259308066097\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(iso)\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "# 전역 중요도(평균 절대값)\n",
    "import numpy as np\n",
    "global_imp = np.mean(np.abs(shap_values), axis=0)\n",
    "\n",
    "idx = np.argsort(global_imp)[::-1]\n",
    "for i in idx:\n",
    "    print(feature_cols[i], global_imp[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998d914",
   "metadata": {},
   "source": [
    "- 없을 때 정확도의 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a60b747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rtn_flow2        drop_f1=0.0140\n",
      "fcv03_pos        drop_f1=0.0128\n",
      "fcv03_cmd        drop_f1=0.0100\n",
      "hx_press         drop_f1=-0.0008\n",
      "rtn_level        drop_f1=-0.0029\n",
      "rtn_flow         drop_f1=-0.0038\n",
      "fcv03_cng        drop_f1=-0.0086\n",
      "fcv03_diff       drop_f1=-0.0101\n",
      "flow_balance_abs  drop_f1=-0.0188\n",
      "phys_diff_abs    drop_f1=-0.0210\n",
      "level_diff_abs   drop_f1=-0.0307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def eval_iso_f1(Xtr, Xte, yte):\n",
    "    m = clone(iso)\n",
    "    m.fit(Xtr)\n",
    "    yhat = (m.predict(Xte) == -1).astype(int)\n",
    "    return f1_score(yte, yhat)\n",
    "\n",
    "base = eval_iso_f1(X_train_scaled, X_test_scaled, y_test)\n",
    "\n",
    "drop_imp = []\n",
    "for j, col in enumerate(feature_cols):\n",
    "    Xtr_drop = np.delete(X_train_scaled, j, axis=1)\n",
    "    Xte_drop = np.delete(X_test_scaled, j, axis=1)\n",
    "    score = eval_iso_f1(Xtr_drop, Xte_drop, y_test)\n",
    "    drop_imp.append(base - score)\n",
    "\n",
    "idx = np.argsort(drop_imp)[::-1]\n",
    "for i in idx:\n",
    "    print(f\"{feature_cols[i]:15s}  drop_f1={drop_imp[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df337843",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4db142",
   "metadata": {},
   "source": [
    "### 1인 라벨에 대해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a963b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def attack_recall_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    y_pred_attack = (y_pred == -1).astype(int)\n",
    "\n",
    "    return recall_score(y, y_pred_attack, pos_label=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc6d3e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcv03_cng        Δattack_recall=0.0159\n",
      "hx_press         Δattack_recall=0.0095\n",
      "fcv03_diff       Δattack_recall=0.0048\n",
      "rtn_level        Δattack_recall=0.0032\n",
      "level_diff_abs   Δattack_recall=0.0000\n",
      "flow_balance_abs  Δattack_recall=-0.0048\n",
      "fcv03_pos        Δattack_recall=-0.0064\n",
      "phys_diff_abs    Δattack_recall=-0.0064\n",
      "fcv03_cmd        Δattack_recall=-0.0079\n",
      "rtn_flow2        Δattack_recall=-0.0095\n",
      "rtn_flow         Δattack_recall=-0.0111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "\n",
    "def eval_attack_recall(Xtr, Xte, yte):\n",
    "    m = clone(iso)\n",
    "    m.fit(Xtr)\n",
    "    yhat = (m.predict(Xte) == -1).astype(int)\n",
    "    return recall_score(yte, yhat, pos_label=1)\n",
    "\n",
    "base_recall = eval_attack_recall(\n",
    "    X_train_scaled,\n",
    "    X_test_scaled,\n",
    "    y_test\n",
    ")\n",
    "\n",
    "drop_imp = []\n",
    "for j, col in enumerate(feature_cols):\n",
    "    Xtr_drop = np.delete(X_train_scaled, j, axis=1)\n",
    "    Xte_drop = np.delete(X_test_scaled, j, axis=1)\n",
    "    r = eval_attack_recall(Xtr_drop, Xte_drop, y_test)\n",
    "    drop_imp.append(base_recall - r)\n",
    "\n",
    "idx = np.argsort(drop_imp)[::-1]\n",
    "for i in idx:\n",
    "    print(f\"{feature_cols[i]:15s}  Δattack_recall={drop_imp[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c083bdc",
   "metadata": {},
   "source": [
    "### 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5e0ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41959   613]\n",
      " [  203   426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     42572\n",
      "           1       0.41      0.68      0.51       629\n",
      "\n",
      "    accuracy                           0.98     43201\n",
      "   macro avg       0.70      0.83      0.75     43201\n",
      "weighted avg       0.99      0.98      0.98     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "feature_cols = [\n",
    "    'flow_balance_abs', 'level_diff_abs',\n",
    "    'fcv03_cng', 'fcv03_diff', \n",
    "    'rtn_level', 'rtn_flow2',\n",
    "    'fcv03_cmd', 'fcv03_pos', 'hx_press'\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "X_test  = test_df[feature_cols]\n",
    "y_test  = test_df['attack']   # 0/1 (test에는 공격 있음)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Isolation Forest (정상만 학습)\n",
    "iso2 = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=0.07,   \n",
    "    random_state=42\n",
    ")\n",
    "iso2.fit(X_train_scaled)\n",
    "\n",
    "# 예측: 정상=1, 이상=-1 로 나옴\n",
    "y_pred_iso2 = iso2.predict(X_test_scaled)\n",
    "\n",
    "# -1 → 공격(1), 1 → 정상(0) 으로 매핑\n",
    "y_pred_attack2 = (y_pred_iso2 == -1).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_attack2))\n",
    "print(classification_report(y_test, y_pred_attack2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d0be9",
   "metadata": {},
   "source": [
    "- 성능향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "feature_cols = [\n",
    "    'flow_balance_abs', 'level_diff_abs',\n",
    "    'fcv03_cng', 'fcv03_diff', \n",
    "    'rtn_level', 'rtn_flow2',\n",
    "    'fcv03_cmd', 'fcv03_pos', 'hx_press'\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "X_test  = test_df[feature_cols]\n",
    "y_test  = test_df['attack']   # 0/1 (test에는 공격 있음)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Isolation Forest (정상만 학습)\n",
    "iso2 = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=0.07,   \n",
    "    random_state=42\n",
    ")\n",
    "iso2.fit(X_train_scaled)\n",
    "\n",
    "# 예측: 정상=1, 이상=-1 로 나옴\n",
    "y_pred_iso2 = iso2.predict(X_test_scaled)\n",
    "\n",
    "# -1 → 공격(1), 1 → 정상(0) 으로 매핑\n",
    "y_pred_attack2 = (y_pred_iso2 == -1).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_attack2))\n",
    "print(classification_report(y_test, y_pred_attack2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c77ebf",
   "metadata": {},
   "source": [
    "## feature 바꿔 가면서 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e8ea398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "base_features = [\n",
    "    'flow_balance_abs', 'level_diff_abs',\n",
    "    'fcv03_cng', 'fcv03_diff', \n",
    "    'rtn_level', 'rtn_flow2',\n",
    "    'fcv03_cmd', 'fcv03_pos', 'hx_press'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cf65311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(features):\n",
    "    Xtr = train_df[features]\n",
    "    Xte = test_df[features]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    Xtr_s = scaler.fit_transform(Xtr)\n",
    "    Xte_s = scaler.transform(Xte)\n",
    "\n",
    "    model = clone(iso)\n",
    "    model.fit(Xtr_s)\n",
    "\n",
    "    y_pred = (model.predict(Xte_s) == -1).astype(int)\n",
    "\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    return recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e23bebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropped</th>\n",
       "      <th>used_features</th>\n",
       "      <th>attack_recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rtn_flow2</td>\n",
       "      <td>[flow_balance_abs, level_diff_abs, fcv03_cng, ...</td>\n",
       "      <td>0.685215</td>\n",
       "      <td>0.489495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fcv03_cmd</td>\n",
       "      <td>[flow_balance_abs, level_diff_abs, fcv03_cng, ...</td>\n",
       "      <td>0.680445</td>\n",
       "      <td>0.494798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fcv03_pos</td>\n",
       "      <td>[flow_balance_abs, level_diff_abs, fcv03_cng, ...</td>\n",
       "      <td>0.680445</td>\n",
       "      <td>0.476615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flow_balance_abs</td>\n",
       "      <td>[level_diff_abs, fcv03_cng, fcv03_diff, rtn_le...</td>\n",
       "      <td>0.678855</td>\n",
       "      <td>0.539141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fcv03_diff</td>\n",
       "      <td>[flow_balance_abs, level_diff_abs, fcv03_cng, ...</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.520196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rtn_level</td>\n",
       "      <td>[flow_balance_abs, level_diff_abs, fcv03_cng, ...</td>\n",
       "      <td>0.670906</td>\n",
       "      <td>0.503881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>level_diff_abs</td>\n",
       "      <td>[flow_balance_abs, fcv03_cng, fcv03_diff, rtn_...</td>\n",
       "      <td>0.669316</td>\n",
       "      <td>0.564343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hx_press</td>\n",
       "      <td>[flow_balance_abs, level_diff_abs, fcv03_cng, ...</td>\n",
       "      <td>0.658188</td>\n",
       "      <td>0.500605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fcv03_cng</td>\n",
       "      <td>[flow_balance_abs, level_diff_abs, fcv03_diff,...</td>\n",
       "      <td>0.645469</td>\n",
       "      <td>0.533509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dropped                                      used_features  \\\n",
       "5         rtn_flow2  [flow_balance_abs, level_diff_abs, fcv03_cng, ...   \n",
       "6         fcv03_cmd  [flow_balance_abs, level_diff_abs, fcv03_cng, ...   \n",
       "7         fcv03_pos  [flow_balance_abs, level_diff_abs, fcv03_cng, ...   \n",
       "0  flow_balance_abs  [level_diff_abs, fcv03_cng, fcv03_diff, rtn_le...   \n",
       "3        fcv03_diff  [flow_balance_abs, level_diff_abs, fcv03_cng, ...   \n",
       "4         rtn_level  [flow_balance_abs, level_diff_abs, fcv03_cng, ...   \n",
       "1    level_diff_abs  [flow_balance_abs, fcv03_cng, fcv03_diff, rtn_...   \n",
       "8          hx_press  [flow_balance_abs, level_diff_abs, fcv03_cng, ...   \n",
       "2         fcv03_cng  [flow_balance_abs, level_diff_abs, fcv03_diff,...   \n",
       "\n",
       "   attack_recall        f1  \n",
       "5       0.685215  0.489495  \n",
       "6       0.680445  0.494798  \n",
       "7       0.680445  0.476615  \n",
       "0       0.678855  0.539141  \n",
       "3       0.675676  0.520196  \n",
       "4       0.670906  0.503881  \n",
       "1       0.669316  0.564343  \n",
       "8       0.658188  0.500605  \n",
       "2       0.645469  0.533509  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1drop = []\n",
    "\n",
    "for f in base_features:\n",
    "    feats = [x for x in base_features if x != f]\n",
    "    recall, f1 = eval_model(feats)\n",
    "\n",
    "    results_1drop.append({\n",
    "        'dropped': f,\n",
    "        'used_features': feats,\n",
    "        'attack_recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "\n",
    "df_1drop = pd.DataFrame(results_1drop)\n",
    "df_1drop.sort_values('attack_recall', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b6c48b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropped_1</th>\n",
       "      <th>dropped_2</th>\n",
       "      <th>attack_recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rtn_flow2</td>\n",
       "      <td>fcv03_cmd</td>\n",
       "      <td>0.689984</td>\n",
       "      <td>0.446272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rtn_flow2</td>\n",
       "      <td>fcv03_pos</td>\n",
       "      <td>0.688394</td>\n",
       "      <td>0.446162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flow_balance_abs</td>\n",
       "      <td>fcv03_cmd</td>\n",
       "      <td>0.685215</td>\n",
       "      <td>0.501454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>fcv03_cmd</td>\n",
       "      <td>fcv03_pos</td>\n",
       "      <td>0.685215</td>\n",
       "      <td>0.470011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fcv03_diff</td>\n",
       "      <td>rtn_flow2</td>\n",
       "      <td>0.685215</td>\n",
       "      <td>0.472588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flow_balance_abs</td>\n",
       "      <td>rtn_flow2</td>\n",
       "      <td>0.683625</td>\n",
       "      <td>0.497685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flow_balance_abs</td>\n",
       "      <td>fcv03_diff</td>\n",
       "      <td>0.682035</td>\n",
       "      <td>0.531599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flow_balance_abs</td>\n",
       "      <td>fcv03_pos</td>\n",
       "      <td>0.682035</td>\n",
       "      <td>0.503817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rtn_level</td>\n",
       "      <td>rtn_flow2</td>\n",
       "      <td>0.682035</td>\n",
       "      <td>0.444790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fcv03_diff</td>\n",
       "      <td>fcv03_pos</td>\n",
       "      <td>0.682035</td>\n",
       "      <td>0.472207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>level_diff_abs</td>\n",
       "      <td>rtn_flow2</td>\n",
       "      <td>0.680445</td>\n",
       "      <td>0.525153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rtn_level</td>\n",
       "      <td>fcv03_pos</td>\n",
       "      <td>0.680445</td>\n",
       "      <td>0.467760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rtn_level</td>\n",
       "      <td>fcv03_cmd</td>\n",
       "      <td>0.680445</td>\n",
       "      <td>0.473713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>level_diff_abs</td>\n",
       "      <td>fcv03_cmd</td>\n",
       "      <td>0.680445</td>\n",
       "      <td>0.526769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fcv03_diff</td>\n",
       "      <td>fcv03_cmd</td>\n",
       "      <td>0.680445</td>\n",
       "      <td>0.482254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>level_diff_abs</td>\n",
       "      <td>fcv03_pos</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.514528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flow_balance_abs</td>\n",
       "      <td>rtn_level</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.500589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>level_diff_abs</td>\n",
       "      <td>fcv03_diff</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.546624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fcv03_diff</td>\n",
       "      <td>rtn_level</td>\n",
       "      <td>0.674086</td>\n",
       "      <td>0.491594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>level_diff_abs</td>\n",
       "      <td>rtn_level</td>\n",
       "      <td>0.672496</td>\n",
       "      <td>0.537143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>fcv03_cmd</td>\n",
       "      <td>hx_press</td>\n",
       "      <td>0.667727</td>\n",
       "      <td>0.495283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flow_balance_abs</td>\n",
       "      <td>level_diff_abs</td>\n",
       "      <td>0.667727</td>\n",
       "      <td>0.591966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>fcv03_pos</td>\n",
       "      <td>hx_press</td>\n",
       "      <td>0.667727</td>\n",
       "      <td>0.491228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rtn_flow2</td>\n",
       "      <td>hx_press</td>\n",
       "      <td>0.664547</td>\n",
       "      <td>0.484919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fcv03_diff</td>\n",
       "      <td>hx_press</td>\n",
       "      <td>0.662957</td>\n",
       "      <td>0.506375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rtn_level</td>\n",
       "      <td>hx_press</td>\n",
       "      <td>0.651828</td>\n",
       "      <td>0.463539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fcv03_cng</td>\n",
       "      <td>fcv03_cmd</td>\n",
       "      <td>0.650238</td>\n",
       "      <td>0.498173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fcv03_cng</td>\n",
       "      <td>fcv03_pos</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.488330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flow_balance_abs</td>\n",
       "      <td>fcv03_cng</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.546917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>level_diff_abs</td>\n",
       "      <td>fcv03_cng</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fcv03_cng</td>\n",
       "      <td>rtn_flow2</td>\n",
       "      <td>0.645469</td>\n",
       "      <td>0.500617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fcv03_cng</td>\n",
       "      <td>fcv03_diff</td>\n",
       "      <td>0.642289</td>\n",
       "      <td>0.514322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flow_balance_abs</td>\n",
       "      <td>hx_press</td>\n",
       "      <td>0.639110</td>\n",
       "      <td>0.528947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fcv03_cng</td>\n",
       "      <td>rtn_level</td>\n",
       "      <td>0.637520</td>\n",
       "      <td>0.494147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fcv03_cng</td>\n",
       "      <td>hx_press</td>\n",
       "      <td>0.632750</td>\n",
       "      <td>0.538201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>level_diff_abs</td>\n",
       "      <td>hx_press</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.530138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dropped_1       dropped_2  attack_recall        f1\n",
       "30         rtn_flow2       fcv03_cmd       0.689984  0.446272\n",
       "31         rtn_flow2       fcv03_pos       0.688394  0.446162\n",
       "5   flow_balance_abs       fcv03_cmd       0.685215  0.501454\n",
       "33         fcv03_cmd       fcv03_pos       0.685215  0.470011\n",
       "22        fcv03_diff       rtn_flow2       0.685215  0.472588\n",
       "4   flow_balance_abs       rtn_flow2       0.683625  0.497685\n",
       "2   flow_balance_abs      fcv03_diff       0.682035  0.531599\n",
       "6   flow_balance_abs       fcv03_pos       0.682035  0.503817\n",
       "26         rtn_level       rtn_flow2       0.682035  0.444790\n",
       "24        fcv03_diff       fcv03_pos       0.682035  0.472207\n",
       "11    level_diff_abs       rtn_flow2       0.680445  0.525153\n",
       "28         rtn_level       fcv03_pos       0.680445  0.467760\n",
       "27         rtn_level       fcv03_cmd       0.680445  0.473713\n",
       "12    level_diff_abs       fcv03_cmd       0.680445  0.526769\n",
       "23        fcv03_diff       fcv03_cmd       0.680445  0.482254\n",
       "13    level_diff_abs       fcv03_pos       0.675676  0.514528\n",
       "3   flow_balance_abs       rtn_level       0.675676  0.500589\n",
       "9     level_diff_abs      fcv03_diff       0.675676  0.546624\n",
       "21        fcv03_diff       rtn_level       0.674086  0.491594\n",
       "10    level_diff_abs       rtn_level       0.672496  0.537143\n",
       "34         fcv03_cmd        hx_press       0.667727  0.495283\n",
       "0   flow_balance_abs  level_diff_abs       0.667727  0.591966\n",
       "35         fcv03_pos        hx_press       0.667727  0.491228\n",
       "32         rtn_flow2        hx_press       0.664547  0.484919\n",
       "25        fcv03_diff        hx_press       0.662957  0.506375\n",
       "29         rtn_level        hx_press       0.651828  0.463539\n",
       "18         fcv03_cng       fcv03_cmd       0.650238  0.498173\n",
       "19         fcv03_cng       fcv03_pos       0.648649  0.488330\n",
       "1   flow_balance_abs       fcv03_cng       0.648649  0.546917\n",
       "8     level_diff_abs       fcv03_cng       0.647059  0.552239\n",
       "17         fcv03_cng       rtn_flow2       0.645469  0.500617\n",
       "15         fcv03_cng      fcv03_diff       0.642289  0.514322\n",
       "7   flow_balance_abs        hx_press       0.639110  0.528947\n",
       "16         fcv03_cng       rtn_level       0.637520  0.494147\n",
       "20         fcv03_cng        hx_press       0.632750  0.538201\n",
       "14    level_diff_abs        hx_press       0.580286  0.530138"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2drop = []\n",
    "\n",
    "for f1, f2 in combinations(base_features, 2):\n",
    "    feats = [x for x in base_features if x not in (f1, f2)]\n",
    "    recall, f1_score_val = eval_model(feats)\n",
    "\n",
    "    results_2drop.append({\n",
    "        'dropped_1': f1,\n",
    "        'dropped_2': f2,\n",
    "        'attack_recall': recall,\n",
    "        'f1': f1_score_val\n",
    "    })\n",
    "\n",
    "df_2drop = pd.DataFrame(results_2drop)\n",
    "df_2drop.sort_values('attack_recall', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "baac6b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42202   370]\n",
      " [  209   420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     42572\n",
      "           1       0.53      0.67      0.59       629\n",
      "\n",
      "    accuracy                           0.99     43201\n",
      "   macro avg       0.76      0.83      0.79     43201\n",
      "weighted avg       0.99      0.99      0.99     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "feature_cols = [\n",
    "    'fcv03_cng', 'fcv03_diff', \n",
    "    'rtn_level', 'rtn_flow2',\n",
    "    'fcv03_cmd', 'fcv03_pos', 'hx_press'\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "X_test  = test_df[feature_cols]\n",
    "y_test  = test_df['attack']   # 0/1 (test에는 공격 있음)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Isolation Forest (정상만 학습)\n",
    "iso3 = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=0.07,   \n",
    "    random_state=42\n",
    ")\n",
    "iso3.fit(X_train_scaled)\n",
    "\n",
    "# 예측: 정상=1, 이상=-1 로 나옴\n",
    "y_pred_iso3 = iso3.predict(X_test_scaled)\n",
    "\n",
    "# -1 → 공격(1), 1 → 정상(0) 으로 매핑\n",
    "y_pred_attack3 = (y_pred_iso3 == -1).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_attack3))\n",
    "print(classification_report(y_test, y_pred_attack3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a23056",
   "metadata": {},
   "source": [
    "## 칼럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c862617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features = [\n",
    "    \"pump1A_cmd\", \"pump1A_run\",\n",
    "    \"pump1B_cmd\", \"pump1B_run\",\n",
    "    \"pump2_cmd\",  \"pump2_run\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f70e66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = [\n",
    "    'fcv03_cng', 'fcv03_diff', \n",
    "    'rtn_level', 'rtn_flow2',\n",
    "    'fcv03_cmd', 'fcv03_pos', 'hx_press'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "932daa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_raw=pd.read_csv('train1.csv')\n",
    "test_df_raw=pd.read_csv('test1.csv')\n",
    "train_df_raw.rename(columns=p1_dict, inplace=True)\n",
    "test_df_raw.rename(columns=p1_dict, inplace=True)\n",
    "train_df_raw = add_custom_features(train_df_raw)\n",
    "test_df_raw  = add_custom_features(test_df_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c74de45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def run_if_eval_from_raw(features, contamination=0.07):\n",
    "    X_train = train_df_raw[features]\n",
    "    X_test  = test_df_raw[features]\n",
    "    y_test  = test_df_raw[\"attack\"].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    iso = IsolationForest(\n",
    "        n_estimators=300,\n",
    "        contamination=contamination,\n",
    "        random_state=42\n",
    "    )\n",
    "    iso.fit(X_train_scaled)\n",
    "\n",
    "    y_pred = (iso.predict(X_test_scaled) == -1).astype(int)\n",
    "\n",
    "    return {\n",
    "        \"precision_1\": precision_score(y_test, y_pred, pos_label=1, zero_division=0),\n",
    "        \"recall_1\":    recall_score(y_test, y_pred, pos_label=1, zero_division=0),\n",
    "        \"f1_1\":        f1_score(y_test, y_pred, pos_label=1, zero_division=0),\n",
    "        \"fp\": int(np.sum((y_test==0) & (y_pred==1))),\n",
    "        \"fn\": int(np.sum((y_test==1) & (y_pred==0))),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ca18db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>added</th>\n",
       "      <th>n_added</th>\n",
       "      <th>features</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pump1A_cmd</td>\n",
       "      <td>1</td>\n",
       "      <td>[fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...</td>\n",
       "      <td>0.542894</td>\n",
       "      <td>0.674086</td>\n",
       "      <td>0.601418</td>\n",
       "      <td>357</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pump1A_run</td>\n",
       "      <td>1</td>\n",
       "      <td>[fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...</td>\n",
       "      <td>0.542894</td>\n",
       "      <td>0.674086</td>\n",
       "      <td>0.601418</td>\n",
       "      <td>357</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pump1B_cmd</td>\n",
       "      <td>1</td>\n",
       "      <td>[fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...</td>\n",
       "      <td>0.542894</td>\n",
       "      <td>0.674086</td>\n",
       "      <td>0.601418</td>\n",
       "      <td>357</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pump1B_run</td>\n",
       "      <td>1</td>\n",
       "      <td>[fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...</td>\n",
       "      <td>0.542894</td>\n",
       "      <td>0.674086</td>\n",
       "      <td>0.601418</td>\n",
       "      <td>357</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pump2_cmd</td>\n",
       "      <td>1</td>\n",
       "      <td>[fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...</td>\n",
       "      <td>0.542894</td>\n",
       "      <td>0.674086</td>\n",
       "      <td>0.601418</td>\n",
       "      <td>357</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pump2_run</td>\n",
       "      <td>1</td>\n",
       "      <td>[fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...</td>\n",
       "      <td>0.542894</td>\n",
       "      <td>0.674086</td>\n",
       "      <td>0.601418</td>\n",
       "      <td>357</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(none)</td>\n",
       "      <td>0</td>\n",
       "      <td>[fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.667727</td>\n",
       "      <td>0.591966</td>\n",
       "      <td>370</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pump1A_cmd+pump1A_run</td>\n",
       "      <td>2</td>\n",
       "      <td>[fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...</td>\n",
       "      <td>0.491587</td>\n",
       "      <td>0.650238</td>\n",
       "      <td>0.559890</td>\n",
       "      <td>423</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pump1A_cmd+pump1B_cmd</td>\n",
       "      <td>2</td>\n",
       "      <td>[fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...</td>\n",
       "      <td>0.491587</td>\n",
       "      <td>0.650238</td>\n",
       "      <td>0.559890</td>\n",
       "      <td>423</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pump1A_cmd+pump1B_run</td>\n",
       "      <td>2</td>\n",
       "      <td>[fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...</td>\n",
       "      <td>0.491587</td>\n",
       "      <td>0.650238</td>\n",
       "      <td>0.559890</td>\n",
       "      <td>423</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   added  n_added  \\\n",
       "1             pump1A_cmd        1   \n",
       "2             pump1A_run        1   \n",
       "3             pump1B_cmd        1   \n",
       "4             pump1B_run        1   \n",
       "5              pump2_cmd        1   \n",
       "6              pump2_run        1   \n",
       "0                 (none)        0   \n",
       "7  pump1A_cmd+pump1A_run        2   \n",
       "8  pump1A_cmd+pump1B_cmd        2   \n",
       "9  pump1A_cmd+pump1B_run        2   \n",
       "\n",
       "                                            features  precision_1  recall_1  \\\n",
       "1  [fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...     0.542894  0.674086   \n",
       "2  [fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...     0.542894  0.674086   \n",
       "3  [fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...     0.542894  0.674086   \n",
       "4  [fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...     0.542894  0.674086   \n",
       "5  [fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...     0.542894  0.674086   \n",
       "6  [fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...     0.542894  0.674086   \n",
       "0  [fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...     0.531646  0.667727   \n",
       "7  [fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...     0.491587  0.650238   \n",
       "8  [fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...     0.491587  0.650238   \n",
       "9  [fcv03_cng, fcv03_diff, rtn_level, rtn_flow2, ...     0.491587  0.650238   \n",
       "\n",
       "       f1_1   fp   fn  \n",
       "1  0.601418  357  205  \n",
       "2  0.601418  357  205  \n",
       "3  0.601418  357  205  \n",
       "4  0.601418  357  205  \n",
       "5  0.601418  357  205  \n",
       "6  0.601418  357  205  \n",
       "0  0.591966  370  209  \n",
       "7  0.559890  423  220  \n",
       "8  0.559890  423  220  \n",
       "9  0.559890  423  220  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "# (0) baseline\n",
    "m = run_if_eval_from_raw(base_features)\n",
    "results.append({\n",
    "    \"added\": \"(none)\",\n",
    "    \"n_added\": 0,\n",
    "    \"features\": base_features,\n",
    "    **m\n",
    "})\n",
    "\n",
    "# (1) add 1\n",
    "for f in extra_features:\n",
    "    feats = base_features + [f]\n",
    "    m = run_if_eval_from_raw(feats)\n",
    "    results.append({\n",
    "        \"added\": f,\n",
    "        \"n_added\": 1,\n",
    "        \"features\": feats,\n",
    "        **m\n",
    "    })\n",
    "\n",
    "# (2) add 2\n",
    "for f1, f2 in combinations(extra_features, 2):\n",
    "    feats = base_features + [f1, f2]\n",
    "    m = run_if_eval_from_raw(feats)\n",
    "    results.append({\n",
    "        \"added\": f\"{f1}+{f2}\",\n",
    "        \"n_added\": 2,\n",
    "        \"features\": feats,\n",
    "        **m\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.sort_values([\"recall_1\", \"f1_1\"], ascending=False).head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2515e21",
   "metadata": {},
   "source": [
    "- pump1A_cmd 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e449e",
   "metadata": {},
   "source": [
    "## 최종 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0e1ba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['fcv03_cng', 'fcv03_diff', 'rtn_level', 'rtn_flow2', 'fcv03_cmd', 'fcv03_pos', 'hx_press', 'pump1A_cmd']\n",
      "[[42215   357]\n",
      " [  205   424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9952    0.9916    0.9934     42572\n",
      "           1     0.5429    0.6741    0.6014       629\n",
      "\n",
      "    accuracy                         0.9870     43201\n",
      "   macro avg     0.7690    0.8329    0.7974     43201\n",
      "weighted avg     0.9886    0.9870    0.9877     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 기본 7개 + pump1A_cmd 1개 추가\n",
    "feature_cols_pump1A = [\n",
    "    'fcv03_cng', 'fcv03_diff',\n",
    "    'rtn_level', 'rtn_flow2',\n",
    "    'fcv03_cmd', 'fcv03_pos', 'hx_press',\n",
    "    'pump1A_cmd'\n",
    "]\n",
    "\n",
    "# ✅ 원본 DF에서 컬럼을 다시 가져와서 조립\n",
    "X_train = train_df_raw[feature_cols_pump1A]\n",
    "X_test  = test_df_raw[feature_cols_pump1A]\n",
    "y_test  = test_df_raw['attack']   # 0/1\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Isolation Forest (정상만 학습)\n",
    "iso_pump1A = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=0.07,\n",
    "    random_state=42\n",
    ")\n",
    "iso_pump1A.fit(X_train_scaled)\n",
    "\n",
    "# 예측: 정상=1, 이상=-1\n",
    "y_pred_iso = iso_pump1A.predict(X_test_scaled)\n",
    "\n",
    "# -1 → 공격(1), 1 → 정상(0)\n",
    "y_pred_attack = (y_pred_iso == -1).astype(int)\n",
    "\n",
    "# 출력\n",
    "print(\"Features:\", feature_cols_pump1A)\n",
    "print(confusion_matrix(y_test, y_pred_attack))\n",
    "print(classification_report(y_test, y_pred_attack, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0173385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Drop-column Importance (Δ attack recall) ===\n",
      "hx_press         Δattack_recall=0.2289\n",
      "fcv03_cng        Δattack_recall=0.0270\n",
      "pump1A_cmd       Δattack_recall=0.0064\n",
      "rtn_flow2        Δattack_recall=0.0000\n",
      "rtn_level        Δattack_recall=-0.0016\n",
      "fcv03_diff       Δattack_recall=-0.0064\n",
      "fcv03_pos        Δattack_recall=-0.0111\n",
      "fcv03_cmd        Δattack_recall=-0.0111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "\n",
    "# pump1A_cmd 포함 feature 목록\n",
    "feature_cols_pump1A = [\n",
    "    'fcv03_cng', 'fcv03_diff',\n",
    "    'rtn_level', 'rtn_flow2',\n",
    "    'fcv03_cmd', 'fcv03_pos', 'hx_press',\n",
    "    'pump1A_cmd'\n",
    "]\n",
    "\n",
    "# attack recall 평가 함수 (IsolationForest)\n",
    "def eval_attack_recall(model, Xtr, Xte, yte):\n",
    "    m = clone(model)\n",
    "    m.fit(Xtr)\n",
    "    yhat = (m.predict(Xte) == -1).astype(int)\n",
    "    return recall_score(yte, yhat, pos_label=1)\n",
    "\n",
    "# 🔹 baseline recall (모든 feature 사용)\n",
    "base_recall = eval_attack_recall(\n",
    "    iso_pump1A,\n",
    "    X_train_scaled,\n",
    "    X_test_scaled,\n",
    "    y_test\n",
    ")\n",
    "\n",
    "# 🔹 drop-column importance\n",
    "drop_imp = []\n",
    "\n",
    "for j, col in enumerate(feature_cols_pump1A):\n",
    "    Xtr_drop = np.delete(X_train_scaled, j, axis=1)\n",
    "    Xte_drop = np.delete(X_test_scaled, j, axis=1)\n",
    "\n",
    "    r = eval_attack_recall(\n",
    "        iso_pump1A,\n",
    "        Xtr_drop,\n",
    "        Xte_drop,\n",
    "        y_test\n",
    "    )\n",
    "\n",
    "    drop_imp.append(base_recall - r)\n",
    "\n",
    "# 중요도 큰 순서로 정렬\n",
    "idx = np.argsort(drop_imp)[::-1]\n",
    "\n",
    "print(\"=== Drop-column Importance (Δ attack recall) ===\")\n",
    "for i in idx:\n",
    "    print(f\"{feature_cols_pump1A[i]:15s}  Δattack_recall={drop_imp[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc187d3",
   "metadata": {},
   "source": [
    "## OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM p= 99  recall=0.569  precision=0.827\n",
      "SVM p= 98  recall=0.680  precision=0.495\n",
      "SVM p= 97  recall=0.690  precision=0.335\n",
      "SVM p= 95  recall=0.701  precision=0.204\n",
      "SVM p= 90  recall=0.727  precision=0.106\n",
      "SVM p= 85  recall=0.750  precision=0.073\n",
      "SVM p= 80  recall=0.766  precision=0.056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "svm = OneClassSVM(\n",
    "    kernel=\"rbf\",\n",
    "    nu=0.03,    \n",
    "    gamma='scale'\n",
    ")\n",
    "svm.fit(X_train_s)\n",
    "\n",
    "scores_svm = -svm.decision_function(X_test_s)\n",
    "\n",
    "for p in [99,98,97,95,90,85,80]:\n",
    "    thr = np.percentile(scores_svm, p)\n",
    "    y_pred = (scores_svm >= thr).astype(int)\n",
    "    r = recall_score(y_true, y_pred)\n",
    "    pr = precision_score(y_true, y_pred)\n",
    "    print(f\"SVM p={p:3d}  recall={r:.3f}  precision={pr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe0e1bf",
   "metadata": {},
   "source": [
    "# autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c817de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [5/50]  loss=0.000336\n",
      "Epoch [10/50]  loss=0.000095\n",
      "Epoch [15/50]  loss=0.000133\n",
      "Epoch [20/50]  loss=0.000139\n",
      "Epoch [25/50]  loss=0.000062\n",
      "Epoch [30/50]  loss=0.000055\n",
      "Epoch [35/50]  loss=0.000057\n",
      "Epoch [40/50]  loss=0.000088\n",
      "Epoch [45/50]  loss=0.000084\n",
      "Epoch [50/50]  loss=0.000076\n",
      "AE p= 99  thr=0.002105  recall=0.531  precision=0.771\n",
      "AE p= 98  thr=0.000491  recall=0.626  precision=0.455\n",
      "AE p= 97  thr=0.000331  recall=0.649  precision=0.315\n",
      "AE p= 95  thr=0.000207  recall=0.672  precision=0.196\n",
      "AE p= 90  thr=0.000107  recall=0.717  precision=0.104\n",
      "AE p= 85  thr=0.000074  recall=0.744  precision=0.072\n",
      "AE p= 80  thr=0.000061  recall=0.765  precision=0.056\n",
      "AE p= 75  thr=0.000053  recall=0.776  precision=0.045\n",
      "AE p= 70  thr=0.000047  recall=0.790  precision=0.038\n",
      "\n",
      "=== Final Threshold Evaluation (p=90) ===\n",
      "threshold: 0.00010671366180758923\n",
      "Confusion Matrix:\n",
      "[[38702  3870]\n",
      " [  178   451]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.909     0.950     42572\n",
      "           1      0.104     0.717     0.182       629\n",
      "\n",
      "    accuracy                          0.906     43201\n",
      "   macro avg      0.550     0.813     0.566     43201\n",
      "weighted avg      0.982     0.906     0.939     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "assert isinstance(X_train, np.ndarray)\n",
    "assert isinstance(X_test, np.ndarray)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor  = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = Autoencoder(input_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "batch_size = 256\n",
    "train_ds = TensorDataset(X_train_tensor)  \n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "n_epochs = 50\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for (x_batch,) in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_recon = model(x_batch)\n",
    "        loss = criterion(x_recon, x_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * x_batch.size(0)\n",
    "    epoch_loss /= len(train_loader.dataset)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}]  loss={epoch_loss:.6f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    X_test_recon  = model(X_test_tensor)\n",
    "    # MSE per sample\n",
    "    recon_error = torch.mean((X_test_tensor - X_test_recon) ** 2, dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "y_true = y_test  # numpy 0/1\n",
    "\n",
    "\n",
    "percentiles = [99, 98, 97, 95, 90, 85, 80, 75, 70]\n",
    "for p in percentiles:\n",
    "    thr = np.percentile(recon_error, p)\n",
    "    y_pred = (recon_error >= thr).astype(int)  # 1=anomaly\n",
    "    r = recall_score(y_true, y_pred)\n",
    "    pr = precision_score(y_true, y_pred)\n",
    "    print(f\"AE p={p:3d}  thr={thr:.6f}  recall={r:.3f}  precision={pr:.3f}\")\n",
    "\n",
    "\n",
    "best_p = 90 \n",
    "thr_best = np.percentile(recon_error, best_p)\n",
    "y_pred_final = (recon_error >= thr_best).astype(int)\n",
    "\n",
    "print(\"\\n=== Final Threshold Evaluation (p=%d) ===\" % best_p)\n",
    "print(\"threshold:\", thr_best)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred_final))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred_final, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "951c04e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\heart\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\heart\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\heart\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\heart\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\heart\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\heart\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "     --------------- ------------------------ 2.4/6.2 MB 11.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 4.7/6.2 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.2/6.2 MB 11.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\heart\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\heart\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\heart\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\heart\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-win_amd64.whl (2532.3 MB)\n",
      "   ---------------------------------------- 0.0/2.5 GB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 GB 12.2 MB/s eta 0:03:28\n",
      "   ---------------------------------------- 0.0/2.5 GB 11.9 MB/s eta 0:03:33\n",
      "   ---------------------------------------- 0.0/2.5 GB 11.2 MB/s eta 0:03:46\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.9 MB/s eta 0:03:53\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.8 MB/s eta 0:03:53\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.5 MB/s eta 0:04:01\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.1 MB/s eta 0:04:09\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.2 MB/s eta 0:04:08\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.2 MB/s eta 0:04:08\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.3 MB/s eta 0:04:04\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.5 MB/s eta 0:04:00\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.6 MB/s eta 0:03:58\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.4 MB/s eta 0:04:00\n",
      "   ---------------------------------------- 0.0/2.5 GB 10.5 MB/s eta 0:04:00\n",
      "    --------------------------------------- 0.0/2.5 GB 10.6 MB/s eta 0:03:56\n",
      "    --------------------------------------- 0.0/2.5 GB 10.6 MB/s eta 0:03:56\n",
      "    --------------------------------------- 0.0/2.5 GB 10.6 MB/s eta 0:03:56\n",
      "    --------------------------------------- 0.0/2.5 GB 10.5 MB/s eta 0:03:57\n",
      "    --------------------------------------- 0.0/2.5 GB 10.6 MB/s eta 0:03:56\n",
      "    --------------------------------------- 0.0/2.5 GB 10.6 MB/s eta 0:03:54\n",
      "    --------------------------------------- 0.0/2.5 GB 10.7 MB/s eta 0:03:53\n",
      "    --------------------------------------- 0.0/2.5 GB 10.7 MB/s eta 0:03:53\n",
      "    --------------------------------------- 0.1/2.5 GB 10.7 MB/s eta 0:03:53\n",
      "    --------------------------------------- 0.1/2.5 GB 10.7 MB/s eta 0:03:52\n",
      "    --------------------------------------- 0.1/2.5 GB 10.7 MB/s eta 0:03:51\n",
      "    --------------------------------------- 0.1/2.5 GB 10.8 MB/s eta 0:03:50\n",
      "    --------------------------------------- 0.1/2.5 GB 10.7 MB/s eta 0:03:51\n",
      "    --------------------------------------- 0.1/2.5 GB 10.8 MB/s eta 0:03:50\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.8 MB/s eta 0:03:49\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.8 MB/s eta 0:03:48\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:47\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:47\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.8 MB/s eta 0:03:48\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.8 MB/s eta 0:03:47\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:46\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:46\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.8 MB/s eta 0:03:46\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:46\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:45\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:44\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:45\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:44\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:44\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:43\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:43\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:43\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:43\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:43\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:42\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:42\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:42\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:42\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:41\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:41\n",
      "   - -------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:41\n",
      "   -- ------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:41\n",
      "   -- ------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:41\n",
      "   -- ------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:40\n",
      "   -- ------------------------------------- 0.1/2.5 GB 11.0 MB/s eta 0:03:39\n",
      "   -- ------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:40\n",
      "   -- ------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:40\n",
      "   -- ------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:39\n",
      "   -- ------------------------------------- 0.1/2.5 GB 11.0 MB/s eta 0:03:39\n",
      "   -- ------------------------------------- 0.1/2.5 GB 11.0 MB/s eta 0:03:38\n",
      "   -- ------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:39\n",
      "   -- ------------------------------------- 0.1/2.5 GB 10.9 MB/s eta 0:03:39\n",
      "   -- ------------------------------------- 0.2/2.5 GB 10.9 MB/s eta 0:03:38\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:37\n",
      "   -- ------------------------------------- 0.2/2.5 GB 10.9 MB/s eta 0:03:38\n",
      "   -- ------------------------------------- 0.2/2.5 GB 10.9 MB/s eta 0:03:37\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:37\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:37\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:36\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:36\n",
      "   -- ------------------------------------- 0.2/2.5 GB 10.9 MB/s eta 0:03:36\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:36\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:35\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:35\n",
      "   -- ------------------------------------- 0.2/2.5 GB 10.9 MB/s eta 0:03:36\n",
      "   -- ------------------------------------- 0.2/2.5 GB 10.9 MB/s eta 0:03:35\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:35\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:34\n",
      "   -- ------------------------------------- 0.2/2.5 GB 11.0 MB/s eta 0:03:34\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.9 MB/s eta 0:03:34\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.9 MB/s eta 0:03:34\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:34\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:32\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:32\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:32\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:32\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:32\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:31\n",
      "   --- ------------------------------------ 0.2/2.5 GB 11.0 MB/s eta 0:03:32\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.9 MB/s eta 0:03:32\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.9 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:34\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:34\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:34\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:33\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:32\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:32\n",
      "   --- ------------------------------------ 0.2/2.5 GB 10.8 MB/s eta 0:03:32\n",
      "   --- ------------------------------------ 0.3/2.5 GB 10.8 MB/s eta 0:03:31\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:31\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:31\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:30\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:30\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:30\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:30\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:30\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:29\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:29\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:29\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:28\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:28\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:27\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:27\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:27\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:27\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:26\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:26\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:25\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:25\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:25\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:25\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:25\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:25\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:25\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:24\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:24\n",
      "   ---- ----------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:24\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:24\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:24\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:24\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:23\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:23\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:23\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:23\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:23\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.9 MB/s eta 0:03:22\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:24\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.8 MB/s eta 0:03:25\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.7 MB/s eta 0:03:26\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.6 MB/s eta 0:03:27\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.6 MB/s eta 0:03:28\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.5 MB/s eta 0:03:30\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.4 MB/s eta 0:03:30\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.5 MB/s eta 0:03:30\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.5 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.3/2.5 GB 10.5 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.4 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.4 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.5 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.5 MB/s eta 0:03:28\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.4 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.4 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.4 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.4 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.4 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:30\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:30\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:30\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:29\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:29\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:29\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:27\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:27\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:27\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:27\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.3 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:29\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:29\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:27\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:27\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:27\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.2 MB/s eta 0:03:27\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.1 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.1 MB/s eta 0:03:28\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.1 MB/s eta 0:03:29\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.0 MB/s eta 0:03:30\n",
      "   ------ --------------------------------- 0.4/2.5 GB 10.0 MB/s eta 0:03:30\n",
      "   ------ --------------------------------- 0.4/2.5 GB 9.9 MB/s eta 0:03:31\n",
      "   ------ --------------------------------- 0.4/2.5 GB 9.9 MB/s eta 0:03:32\n",
      "   ------ --------------------------------- 0.4/2.5 GB 9.9 MB/s eta 0:03:32\n",
      "   ------ --------------------------------- 0.4/2.5 GB 9.9 MB/s eta 0:03:32\n",
      "   ------- -------------------------------- 0.4/2.5 GB 9.9 MB/s eta 0:03:32\n",
      "   ------- -------------------------------- 0.4/2.5 GB 9.8 MB/s eta 0:03:32\n",
      "   ------- -------------------------------- 0.4/2.5 GB 9.8 MB/s eta 0:03:33\n",
      "   ------- -------------------------------- 0.4/2.5 GB 9.8 MB/s eta 0:03:33\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:33\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:32\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:32\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:32\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:32\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:32\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:31\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:31\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:31\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:31\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:31\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:30\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:30\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.8 MB/s eta 0:03:30\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:28\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:27\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:26\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:26\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:26\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:26\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:25\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:25\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:24\n",
      "   ------- -------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:25\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:25\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:24\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:24\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:24\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:24\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:23\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:23\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:23\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:22\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:22\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:22\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:22\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:21\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:21\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:23\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:23\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:22\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:22\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:22\n",
      "   -------- ------------------------------- 0.5/2.5 GB 9.9 MB/s eta 0:03:21\n",
      "   -------- ------------------------------- 0.6/2.5 GB 9.9 MB/s eta 0:03:21\n",
      "   -------- ------------------------------- 0.6/2.5 GB 9.9 MB/s eta 0:03:21\n",
      "   -------- ------------------------------- 0.6/2.5 GB 9.9 MB/s eta 0:03:21\n",
      "   -------- ------------------------------- 0.6/2.5 GB 9.8 MB/s eta 0:03:21\n",
      "   -------- ------------------------------- 0.6/2.5 GB 9.8 MB/s eta 0:03:21\n",
      "   -------- ------------------------------- 0.6/2.5 GB 9.9 MB/s eta 0:03:20\n",
      "   -------- ------------------------------- 0.6/2.5 GB 9.9 MB/s eta 0:03:20\n",
      "   -------- ------------------------------- 0.6/2.5 GB 9.8 MB/s eta 0:03:20\n",
      "   -------- ------------------------------- 0.6/2.5 GB 9.8 MB/s eta 0:03:20\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.8 MB/s eta 0:03:21\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.8 MB/s eta 0:03:21\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.7 MB/s eta 0:03:22\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.7 MB/s eta 0:03:22\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.8 MB/s eta 0:03:21\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.8 MB/s eta 0:03:21\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.8 MB/s eta 0:03:20\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.8 MB/s eta 0:03:20\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.8 MB/s eta 0:03:20\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.7 MB/s eta 0:03:20\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.8 MB/s eta 0:03:19\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.8 MB/s eta 0:03:19\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.7 MB/s eta 0:03:19\n",
      "   --------- ------------------------------ 0.6/2.5 GB 9.8 MB/s eta 0:03:17\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:12\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:11\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:11\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:11\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:11\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:10\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:10\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:09\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:09\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:09\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.1 MB/s eta 0:03:09\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.2 MB/s eta 0:03:07\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.2 MB/s eta 0:03:06\n",
      "   --------- ------------------------------ 0.6/2.5 GB 10.2 MB/s eta 0:03:06\n",
      "   ---------- ----------------------------- 0.6/2.5 GB 10.2 MB/s eta 0:03:06\n",
      "   ---------- ----------------------------- 0.6/2.5 GB 10.2 MB/s eta 0:03:06\n",
      "   ---------- ----------------------------- 0.6/2.5 GB 10.2 MB/s eta 0:03:05\n",
      "   ---------- ----------------------------- 0.6/2.5 GB 10.3 MB/s eta 0:03:05\n",
      "   ---------- ----------------------------- 0.6/2.5 GB 10.2 MB/s eta 0:03:05\n",
      "   ---------- ----------------------------- 0.6/2.5 GB 10.2 MB/s eta 0:03:05\n",
      "   ---------- ----------------------------- 0.6/2.5 GB 10.2 MB/s eta 0:03:06\n",
      "   ---------- ----------------------------- 0.6/2.5 GB 10.2 MB/s eta 0:03:06\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.2 MB/s eta 0:03:05\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.2 MB/s eta 0:03:05\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.2 MB/s eta 0:03:05\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.2 MB/s eta 0:03:05\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.2 MB/s eta 0:03:05\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.2 MB/s eta 0:03:04\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.2 MB/s eta 0:03:04\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.2 MB/s eta 0:03:03\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:03:02\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:03:01\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:03:01\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:03:01\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:03:00\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:03:00\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:03:00\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:03:00\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:03:00\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:02:59\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.3 MB/s eta 0:02:59\n",
      "   ---------- ----------------------------- 0.7/2.5 GB 10.4 MB/s eta 0:02:57\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.5 MB/s eta 0:02:56\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.6 MB/s eta 0:02:54\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.6 MB/s eta 0:02:53\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.6 MB/s eta 0:02:52\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.6 MB/s eta 0:02:52\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.7 MB/s eta 0:02:51\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:49\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:49\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:49\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.7 MB/s eta 0:02:49\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.7 MB/s eta 0:02:49\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:49\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:48\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:48\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:48\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:48\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:48\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:47\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:47\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:47\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:47\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:46\n",
      "   ----------- ---------------------------- 0.7/2.5 GB 10.8 MB/s eta 0:02:46\n",
      "   ----------- ---------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:46\n",
      "   ----------- ---------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:46\n",
      "   ----------- ---------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:46\n",
      "   ----------- ---------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:46\n",
      "   ----------- ---------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:43\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:43\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:43\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:42\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.8 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.8 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.8 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.8 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:40\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:39\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.7 MB/s eta 0:02:39\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.8 MB/s eta 0:02:39\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.8 MB/s eta 0:02:38\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.9 MB/s eta 0:02:37\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.9 MB/s eta 0:02:36\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.9 MB/s eta 0:02:36\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.9 MB/s eta 0:02:35\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.9 MB/s eta 0:02:35\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.9 MB/s eta 0:02:36\n",
      "   ------------- -------------------------- 0.8/2.5 GB 10.9 MB/s eta 0:02:35\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.9 MB/s eta 0:02:35\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.9 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.9 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.9 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.9 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.9 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.9 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.9 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.9 MB/s eta 0:02:33\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.8 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.8 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.8 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.8 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.8 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.8 MB/s eta 0:02:33\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.8 MB/s eta 0:02:33\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.8 MB/s eta 0:02:34\n",
      "   ------------- -------------------------- 0.9/2.5 GB 10.7 MB/s eta 0:02:34\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.7 MB/s eta 0:02:35\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.6 MB/s eta 0:02:35\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.6 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.5 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.5 MB/s eta 0:02:37\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.5 MB/s eta 0:02:37\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.5 MB/s eta 0:02:37\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.5 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:37\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.5 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.5 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:37\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:37\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.5 MB/s eta 0:02:35\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:36\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:35\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:35\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:35\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:35\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:35\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:34\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:34\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:34\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:34\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:34\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.4 MB/s eta 0:02:34\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.3 MB/s eta 0:02:34\n",
      "   -------------- ------------------------- 0.9/2.5 GB 10.3 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 0.9/2.5 GB 10.3 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:33\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:33\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:33\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:33\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:33\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.3 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.1 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.2 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.1 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.1 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.1 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.1 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 1.0/2.5 GB 10.1 MB/s eta 0:02:31\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:31\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:31\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:31\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:30\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:28\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:28\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:28\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:28\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.1 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.0 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.0 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.0 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.0 MB/s eta 0:02:30\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.0 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.0/2.5 GB 10.0 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 10.0 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 10.0 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.9 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.9 MB/s eta 0:02:30\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:30\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:30\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:30\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:30\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:30\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:29\n",
      "   ---------------- ----------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:29\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:29\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:30\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:31\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:30\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:30\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:30\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:30\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:29\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:29\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:29\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:27\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:27\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:27\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:27\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:27\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:27\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:25\n",
      "   ------------------ --------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:25\n",
      "   ------------------ --------------------- 1.1/2.5 GB 9.6 MB/s eta 0:02:25\n",
      "   ------------------ --------------------- 1.1/2.5 GB 9.7 MB/s eta 0:02:23\n",
      "   ------------------ --------------------- 1.1/2.5 GB 9.8 MB/s eta 0:02:22\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.8 MB/s eta 0:02:21\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:20\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:19\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:20\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:20\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:19\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:19\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:19\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:18\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:17\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:17\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:17\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:16\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:16\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:15\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:15\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:15\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:15\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:15\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:15\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:15\n",
      "   ------------------ --------------------- 1.2/2.5 GB 9.9 MB/s eta 0:02:15\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:14\n",
      "   ------------------ --------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:14\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:14\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:14\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:13\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:12\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:12\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:10\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:10\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:10\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:10\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.1 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 1.2/2.5 GB 10.0 MB/s eta 0:02:08\n",
      "   ------------------- -------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:08\n",
      "   ------------------- -------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:08\n",
      "   ------------------- -------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:07\n",
      "   ------------------- -------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:07\n",
      "   ------------------- -------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:06\n",
      "   ------------------- -------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:06\n",
      "   ------------------- -------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:05\n",
      "   ------------------- -------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:06\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:06\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:06\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:04\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:04\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.1 MB/s eta 0:02:04\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:04\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:03\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:03\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:03\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:03\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:03\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:02\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:02\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:02\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:02\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.2 MB/s eta 0:02:01\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.3 MB/s eta 0:02:00\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.3 MB/s eta 0:01:59\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.3 MB/s eta 0:01:59\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.3 MB/s eta 0:01:59\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.3 MB/s eta 0:01:58\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.4 MB/s eta 0:01:58\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.5 MB/s eta 0:01:57\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.5 MB/s eta 0:01:56\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.5 MB/s eta 0:01:56\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.5 MB/s eta 0:01:56\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.5 MB/s eta 0:01:56\n",
      "   -------------------- ------------------- 1.3/2.5 GB 10.4 MB/s eta 0:01:56\n",
      "   --------------------- ------------------ 1.3/2.5 GB 10.4 MB/s eta 0:01:56\n",
      "   --------------------- ------------------ 1.3/2.5 GB 10.5 MB/s eta 0:01:55\n",
      "   --------------------- ------------------ 1.3/2.5 GB 10.5 MB/s eta 0:01:55\n",
      "   --------------------- ------------------ 1.3/2.5 GB 10.5 MB/s eta 0:01:55\n",
      "   --------------------- ------------------ 1.3/2.5 GB 10.5 MB/s eta 0:01:54\n",
      "   --------------------- ------------------ 1.3/2.5 GB 10.6 MB/s eta 0:01:53\n",
      "   --------------------- ------------------ 1.3/2.5 GB 10.6 MB/s eta 0:01:53\n",
      "   --------------------- ------------------ 1.3/2.5 GB 10.6 MB/s eta 0:01:53\n",
      "   --------------------- ------------------ 1.3/2.5 GB 10.6 MB/s eta 0:01:52\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.6 MB/s eta 0:01:52\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.6 MB/s eta 0:01:52\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.6 MB/s eta 0:01:52\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.6 MB/s eta 0:01:52\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.6 MB/s eta 0:01:51\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.5 MB/s eta 0:01:52\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.5 MB/s eta 0:01:51\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.6 MB/s eta 0:01:51\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.6 MB/s eta 0:01:51\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.5 MB/s eta 0:01:51\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.6 MB/s eta 0:01:50\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.6 MB/s eta 0:01:50\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.6 MB/s eta 0:01:49\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.7 MB/s eta 0:01:48\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.7 MB/s eta 0:01:48\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.7 MB/s eta 0:01:48\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.7 MB/s eta 0:01:48\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.7 MB/s eta 0:01:48\n",
      "   --------------------- ------------------ 1.4/2.5 GB 10.7 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.7 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.7 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.7 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.5 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.5 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.5 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.5 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.5 MB/s eta 0:01:47\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.5 MB/s eta 0:01:46\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:45\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:45\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:45\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:45\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:44\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:44\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:44\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:44\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:44\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:44\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:43\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:43\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:43\n",
      "   ---------------------- ----------------- 1.4/2.5 GB 10.6 MB/s eta 0:01:43\n",
      "   ---------------------- ----------------- 1.5/2.5 GB 10.6 MB/s eta 0:01:42\n",
      "   ---------------------- ----------------- 1.5/2.5 GB 10.6 MB/s eta 0:01:42\n",
      "   ---------------------- ----------------- 1.5/2.5 GB 10.6 MB/s eta 0:01:43\n",
      "   ---------------------- ----------------- 1.5/2.5 GB 10.5 MB/s eta 0:01:43\n",
      "   ---------------------- ----------------- 1.5/2.5 GB 10.5 MB/s eta 0:01:43\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:43\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:43\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:43\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:43\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:43\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:43\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:43\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:42\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:42\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:42\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:42\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:42\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:42\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:41\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:41\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:41\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:41\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.3 MB/s eta 0:01:41\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:40\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:40\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:40\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:40\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:39\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:39\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:39\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:39\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:39\n",
      "   ----------------------- ---------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:38\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:38\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:38\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:38\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:36\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:36\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:36\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:36\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:35\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:35\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:35\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:35\n",
      "   ------------------------ --------------- 1.5/2.5 GB 10.4 MB/s eta 0:01:35\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:34\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:34\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:34\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:34\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.5 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.5 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:32\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:31\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:31\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:31\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:31\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:31\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:31\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:31\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:31\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:27\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:27\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:27\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:27\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:27\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:26\n",
      "   ------------------------- -------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:26\n",
      "   -------------------------- ------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:26\n",
      "   -------------------------- ------------- 1.6/2.5 GB 10.4 MB/s eta 0:01:26\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:25\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:25\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:25\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:25\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:25\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:24\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:24\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:24\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:23\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:23\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:23\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:23\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:23\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:22\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:22\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:23\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:22\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:22\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:22\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:22\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:22\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:21\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:21\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:21\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:21\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.4 MB/s eta 0:01:21\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.3 MB/s eta 0:01:21\n",
      "   -------------------------- ------------- 1.7/2.5 GB 10.3 MB/s eta 0:01:20\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.3 MB/s eta 0:01:20\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.3 MB/s eta 0:01:20\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.4 MB/s eta 0:01:19\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.5 MB/s eta 0:01:18\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.5 MB/s eta 0:01:18\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.5 MB/s eta 0:01:18\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.5 MB/s eta 0:01:17\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.6 MB/s eta 0:01:17\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.6 MB/s eta 0:01:17\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.6 MB/s eta 0:01:16\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.6 MB/s eta 0:01:16\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.6 MB/s eta 0:01:16\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.6 MB/s eta 0:01:16\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.6 MB/s eta 0:01:15\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.6 MB/s eta 0:01:15\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.6 MB/s eta 0:01:15\n",
      "   --------------------------- ------------ 1.7/2.5 GB 10.6 MB/s eta 0:01:15\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:14\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:14\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:14\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:13\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:13\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:13\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:13\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:13\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:13\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:12\n",
      "   --------------------------- ------------ 1.8/2.5 GB 10.6 MB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.5 MB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.6 MB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.5 MB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.5 MB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.5 MB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.5 MB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.5 MB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.4 MB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.4 MB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.4 MB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.5 MB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.4 MB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 1.8/2.5 GB 10.4 MB/s eta 0:01:07\n",
      "   ----------------------------- ---------- 1.8/2.5 GB 10.5 MB/s eta 0:01:07\n",
      "   ----------------------------- ---------- 1.8/2.5 GB 10.5 MB/s eta 0:01:07\n",
      "   ----------------------------- ---------- 1.8/2.5 GB 10.5 MB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 1.8/2.5 GB 10.4 MB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 1.8/2.5 GB 10.4 MB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 1.8/2.5 GB 10.5 MB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.5 MB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.6 MB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.6 MB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.6 MB/s eta 0:01:01\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.6 MB/s eta 0:01:01\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.6 MB/s eta 0:01:01\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.6 MB/s eta 0:01:01\n",
      "   ----------------------------- ---------- 1.9/2.5 GB 10.6 MB/s eta 0:01:01\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:01:00\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:01:00\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:01:00\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:59\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:59\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:59\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:59\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:59\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:59\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:58\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:58\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:58\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:58\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:58\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:57\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:57\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:57\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:57\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:56\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:56\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.7 MB/s eta 0:00:56\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.7 MB/s eta 0:00:55\n",
      "   ------------------------------ --------- 1.9/2.5 GB 10.6 MB/s eta 0:00:55\n",
      "   ------------------------------ --------- 2.0/2.5 GB 10.7 MB/s eta 0:00:55\n",
      "   ------------------------------ --------- 2.0/2.5 GB 10.7 MB/s eta 0:00:55\n",
      "   ------------------------------ --------- 2.0/2.5 GB 10.7 MB/s eta 0:00:55\n",
      "   ------------------------------ --------- 2.0/2.5 GB 10.7 MB/s eta 0:00:54\n",
      "   ------------------------------ --------- 2.0/2.5 GB 10.7 MB/s eta 0:00:54\n",
      "   ------------------------------ --------- 2.0/2.5 GB 10.7 MB/s eta 0:00:54\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:54\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:53\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:53\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:53\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:53\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:52\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:52\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:52\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:52\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:52\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:51\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:51\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:51\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:51\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:50\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:50\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:50\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:50\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:50\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:49\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:49\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:49\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:49\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.7 MB/s eta 0:00:49\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.8 MB/s eta 0:00:48\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.8 MB/s eta 0:00:48\n",
      "   ------------------------------- -------- 2.0/2.5 GB 10.8 MB/s eta 0:00:48\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.8 MB/s eta 0:00:47\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.8 MB/s eta 0:00:47\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.8 MB/s eta 0:00:47\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.8 MB/s eta 0:00:47\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.7 MB/s eta 0:00:47\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.7 MB/s eta 0:00:47\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.7 MB/s eta 0:00:47\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.7 MB/s eta 0:00:46\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.7 MB/s eta 0:00:46\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.7 MB/s eta 0:00:46\n",
      "   -------------------------------- ------- 2.0/2.5 GB 10.7 MB/s eta 0:00:46\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.7 MB/s eta 0:00:46\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.7 MB/s eta 0:00:45\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.7 MB/s eta 0:00:45\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.7 MB/s eta 0:00:45\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.7 MB/s eta 0:00:44\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.7 MB/s eta 0:00:44\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.8 MB/s eta 0:00:44\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.8 MB/s eta 0:00:44\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.7 MB/s eta 0:00:44\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.7 MB/s eta 0:00:43\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.7 MB/s eta 0:00:43\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.8 MB/s eta 0:00:43\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.8 MB/s eta 0:00:42\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.8 MB/s eta 0:00:42\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.8 MB/s eta 0:00:42\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.9 MB/s eta 0:00:42\n",
      "   -------------------------------- ------- 2.1/2.5 GB 10.9 MB/s eta 0:00:41\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:41\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:41\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:41\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:40\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:40\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:40\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:40\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:40\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:39\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:39\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.8 MB/s eta 0:00:39\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:39\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:39\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:38\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:38\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:38\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:38\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:37\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:37\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:37\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:37\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:36\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:36\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:36\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.9 MB/s eta 0:00:36\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.8 MB/s eta 0:00:36\n",
      "   --------------------------------- ------ 2.1/2.5 GB 10.8 MB/s eta 0:00:36\n",
      "   --------------------------------- ------ 2.2/2.5 GB 10.8 MB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:34\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:34\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:34\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:34\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.8 MB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:31\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:31\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:31\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:31\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:30\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:30\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:30\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:30\n",
      "   ---------------------------------- ----- 2.2/2.5 GB 10.9 MB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 2.2/2.5 GB 10.9 MB/s eta 0:00:26\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.9 MB/s eta 0:00:26\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.9 MB/s eta 0:00:26\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.9 MB/s eta 0:00:26\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.9 MB/s eta 0:00:26\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.9 MB/s eta 0:00:26\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.8 MB/s eta 0:00:26\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.8 MB/s eta 0:00:25\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.8 MB/s eta 0:00:25\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.9 MB/s eta 0:00:25\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.9 MB/s eta 0:00:25\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.9 MB/s eta 0:00:24\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.8 MB/s eta 0:00:24\n",
      "   ----------------------------------- ---- 2.3/2.5 GB 10.9 MB/s eta 0:00:24\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:24\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:24\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:23\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:23\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:23\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:23\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:23\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.8 MB/s eta 0:00:22\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:22\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:22\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:22\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:21\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:21\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:21\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:21\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:20\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:20\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:20\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:20\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:20\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:19\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:19\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:19\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:19\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:19\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:18\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:18\n",
      "   ------------------------------------ --- 2.3/2.5 GB 10.9 MB/s eta 0:00:18\n",
      "   ------------------------------------- -- 2.3/2.5 GB 10.9 MB/s eta 0:00:18\n",
      "   ------------------------------------- -- 2.3/2.5 GB 10.9 MB/s eta 0:00:18\n",
      "   ------------------------------------- -- 2.3/2.5 GB 10.9 MB/s eta 0:00:17\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:17\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:17\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:17\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:16\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:16\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:16\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:16\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:16\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.8 MB/s eta 0:00:15\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:14\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.8 MB/s eta 0:00:13\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.8 MB/s eta 0:00:13\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.8 MB/s eta 0:00:13\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:13\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.9 MB/s eta 0:00:12\n",
      "   ------------------------------------- -- 2.4/2.5 GB 10.8 MB/s eta 0:00:12\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.8 MB/s eta 0:00:12\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:12\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:12\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:11\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:11\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:11\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:11\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:11\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:10\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:10\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:10\n",
      "   -------------------------------------- - 2.4/2.5 GB 11.0 MB/s eta 0:00:10\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:09\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:09\n",
      "   -------------------------------------- - 2.4/2.5 GB 11.0 MB/s eta 0:00:09\n",
      "   -------------------------------------- - 2.4/2.5 GB 11.0 MB/s eta 0:00:09\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:09\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 2.4/2.5 GB 10.9 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 2.5/2.5 GB 11.0 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 2.5/2.5 GB 11.0 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 2.5/2.5 GB 10.9 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 2.5/2.5 GB 10.9 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.5 GB 10.9 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.5 GB 10.9 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.5 GB 10.9 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.5 GB 10.9 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 2.5/2.5 GB 10.9 MB/s eta 0:00:06\n",
      "   ---------------------------------------  2.5/2.5 GB 11.0 MB/s eta 0:00:06\n",
      "   ---------------------------------------  2.5/2.5 GB 11.0 MB/s eta 0:00:06\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:06\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:05\n",
      "   ---------------------------------------  2.5/2.5 GB 11.0 MB/s eta 0:00:05\n",
      "   ---------------------------------------  2.5/2.5 GB 11.0 MB/s eta 0:00:05\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:05\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:05\n",
      "   ---------------------------------------  2.5/2.5 GB 10.8 MB/s eta 0:00:05\n",
      "   ---------------------------------------  2.5/2.5 GB 10.8 MB/s eta 0:00:04\n",
      "   ---------------------------------------  2.5/2.5 GB 10.8 MB/s eta 0:00:04\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:04\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:04\n",
      "   ---------------------------------------  2.5/2.5 GB 10.8 MB/s eta 0:00:04\n",
      "   ---------------------------------------  2.5/2.5 GB 10.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.5/2.5 GB 10.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 GB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 GB 9.9 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-win_amd64.whl (6.1 MB)\n",
      "   ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 2.1/6.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.1/6.1 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-win_amd64.whl (4.2 MB)\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.2 MB 1.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.6/4.2 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.4/4.2 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.2/4.2 MB 4.9 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed sympy-1.13.1 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a5795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [5/50]  loss=0.001156\n",
      "Epoch [10/50]  loss=0.000952\n",
      "Epoch [15/50]  loss=0.000898\n",
      "Epoch [20/50]  loss=0.000670\n",
      "Epoch [25/50]  loss=0.000816\n",
      "Epoch [30/50]  loss=0.000560\n",
      "Epoch [35/50]  loss=0.000743\n",
      "Epoch [40/50]  loss=0.000349\n",
      "Epoch [45/50]  loss=0.000350\n",
      "Epoch [50/50]  loss=0.000503\n",
      "AE p= 99  thr=0.030919  recall=0.480  precision=0.697\n",
      "AE p= 98  thr=0.005657  recall=0.671  precision=0.488\n",
      "AE p= 97  thr=0.003715  recall=0.682  precision=0.331\n",
      "AE p= 95  thr=0.002615  recall=0.695  precision=0.202\n",
      "AE p= 90  thr=0.001720  recall=0.715  precision=0.104\n",
      "AE p= 85  thr=0.001343  recall=0.734  precision=0.071\n",
      "AE p= 80  thr=0.001103  recall=0.755  precision=0.055\n",
      "AE p= 75  thr=0.000926  recall=0.765  precision=0.045\n",
      "AE p= 70  thr=0.000788  recall=0.777  precision=0.038\n",
      "\n",
      "=== Final Threshold Evaluation (p=90) ===\n",
      "threshold: 0.001720063854008913\n",
      "Confusion Matrix:\n",
      "[[38701  3871]\n",
      " [  179   450]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.909     0.950     42572\n",
      "           1      0.104     0.715     0.182       629\n",
      "\n",
      "    accuracy                          0.906     43201\n",
      "   macro avg      0.550     0.812     0.566     43201\n",
      "weighted avg      0.982     0.906     0.939     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\n",
    "assert isinstance(X_train, np.ndarray)\n",
    "assert isinstance(X_test, np.ndarray)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor  = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Linear(input_dim, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 32),\n",
    "        nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, input_dim),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = Autoencoder(input_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "batch_size = 256\n",
    "train_ds = TensorDataset(X_train_tensor)  \n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "n_epochs = 50\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for (x_batch,) in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_recon = model(x_batch)\n",
    "        loss = criterion(x_recon, x_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * x_batch.size(0)\n",
    "    epoch_loss /= len(train_loader.dataset)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}]  loss={epoch_loss:.6f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    X_test_recon  = model(X_test_tensor)\n",
    "    # MSE per sample\n",
    "    recon_error = torch.mean((X_test_tensor - X_test_recon) ** 2, dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "y_true = y_test  # numpy 0/1\n",
    "\n",
    "\n",
    "percentiles = [99, 98, 97, 95, 90, 85, 80, 75, 70]\n",
    "for p in percentiles:\n",
    "    thr = np.percentile(recon_error, p)\n",
    "    y_pred = (recon_error >= thr).astype(int)  # 1=anomaly\n",
    "    r = recall_score(y_true, y_pred)\n",
    "    pr = precision_score(y_true, y_pred)\n",
    "    print(f\"AE p={p:3d}  thr={thr:.6f}  recall={r:.3f}  precision={pr:.3f}\")\n",
    "\n",
    "\n",
    "best_p = 90 \n",
    "thr_best = np.percentile(recon_error, best_p)\n",
    "y_pred_final = (recon_error >= thr_best).astype(int)\n",
    "\n",
    "print(\"\\n=== Final Threshold Evaluation (p=%d) ===\" % best_p)\n",
    "print(\"threshold:\", thr_best)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred_final))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred_final, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13311d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [5/100]  loss=0.020449\n",
      "Epoch [10/100]  loss=0.018225\n",
      "Epoch [15/100]  loss=0.016121\n",
      "Epoch [20/100]  loss=0.015498\n",
      "Epoch [25/100]  loss=0.014960\n",
      "Epoch [30/100]  loss=0.013992\n",
      "Epoch [35/100]  loss=0.013873\n",
      "Epoch [40/100]  loss=0.012871\n",
      "Epoch [45/100]  loss=0.012392\n",
      "Epoch [50/100]  loss=0.012017\n",
      "Epoch [55/100]  loss=0.011889\n",
      "Epoch [60/100]  loss=0.011374\n",
      "Epoch [65/100]  loss=0.010901\n",
      "Epoch [70/100]  loss=0.010353\n",
      "Epoch [75/100]  loss=0.010446\n",
      "Epoch [80/100]  loss=0.009993\n",
      "Epoch [85/100]  loss=0.009876\n",
      "Epoch [90/100]  loss=0.009716\n",
      "Epoch [95/100]  loss=0.009634\n",
      "Epoch [100/100]  loss=0.009033\n",
      "AE p= 99  thr=0.002873  recall=0.541  precision=0.785\n",
      "AE p= 98  thr=0.000520  recall=0.682  precision=0.496\n",
      "AE p= 97  thr=0.000365  recall=0.696  precision=0.338\n",
      "AE p= 95  thr=0.000275  recall=0.704  precision=0.205\n",
      "AE p= 90  thr=0.000204  recall=0.723  precision=0.105\n",
      "AE p= 85  thr=0.000172  recall=0.734  precision=0.071\n",
      "AE p= 80  thr=0.000151  recall=0.763  precision=0.056\n",
      "AE p= 75  thr=0.000133  recall=0.776  precision=0.045\n",
      "AE p= 70  thr=0.000119  recall=0.797  precision=0.039\n",
      "\n",
      "=== Final Threshold Evaluation (p=90) ===\n",
      "threshold: 0.00020388943084981292\n",
      "Confusion Matrix:\n",
      "[[38706  3866]\n",
      " [  174   455]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.909     0.950     42572\n",
      "           1      0.105     0.723     0.184       629\n",
      "\n",
      "    accuracy                          0.906     43201\n",
      "   macro avg      0.550     0.816     0.567     43201\n",
      "weighted avg      0.983     0.906     0.939     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\n",
    "assert isinstance(X_train, np.ndarray)\n",
    "assert isinstance(X_test, np.ndarray)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor  = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Linear(input_dim, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 32),\n",
    "        nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, input_dim),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = Autoencoder(input_dim).to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "batch_size = 256\n",
    "train_ds = TensorDataset(X_train_tensor)  \n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "n_epochs = 100\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for (x_batch,) in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_recon = model(x_batch)\n",
    "        loss = criterion(x_recon, x_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * x_batch.size(0)\n",
    "    epoch_loss /= len(train_loader.dataset)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}]  loss={epoch_loss:.6f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    X_test_recon  = model(X_test_tensor)\n",
    "    # MSE per sample\n",
    "    recon_error = torch.mean((X_test_tensor - X_test_recon) ** 2, dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "y_true = y_test  # numpy 0/1\n",
    "\n",
    "\n",
    "percentiles = [99, 98, 97, 95, 90, 85, 80, 75, 70]\n",
    "for p in percentiles:\n",
    "    thr = np.percentile(recon_error, p)\n",
    "    y_pred = (recon_error >= thr).astype(int)  \n",
    "    r = recall_score(y_true, y_pred)\n",
    "    pr = precision_score(y_true, y_pred)\n",
    "    print(f\"AE p={p:3d}  thr={thr:.6f}  recall={r:.3f}  precision={pr:.3f}\")\n",
    "\n",
    "\n",
    "best_p = 90\n",
    "thr_best = np.percentile(recon_error, best_p)\n",
    "y_pred_final = (recon_error >= thr_best).astype(int)\n",
    "\n",
    "print(\"\\n=== Final Threshold Evaluation (p=%d) ===\" % best_p)\n",
    "print(\"threshold:\", thr_best)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred_final))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred_final, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dc6c5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Threshold Evaluation (p=10) ===\n",
      "threshold: 2.868662886612583e-05\n",
      "Confusion Matrix:\n",
      "[[ 4308 38264]\n",
      " [   12   617]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.997     0.101     0.184     42572\n",
      "           1      0.016     0.981     0.031       629\n",
      "\n",
      "    accuracy                          0.114     43201\n",
      "   macro avg      0.507     0.541     0.107     43201\n",
      "weighted avg      0.983     0.114     0.182     43201\n",
      "\n",
      "\n",
      "=== Final Threshold Evaluation (p=20) ===\n",
      "threshold: 3.932914842152968e-05\n",
      "Confusion Matrix:\n",
      "[[ 8611 33961]\n",
      " [   29   600]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.997     0.202     0.336     42572\n",
      "           1      0.017     0.954     0.034       629\n",
      "\n",
      "    accuracy                          0.213     43201\n",
      "   macro avg      0.507     0.578     0.185     43201\n",
      "weighted avg      0.982     0.213     0.332     43201\n",
      "\n",
      "\n",
      "=== Final Threshold Evaluation (p=30) ===\n",
      "threshold: 4.9847792979562655e-05\n",
      "Confusion Matrix:\n",
      "[[12921 29651]\n",
      " [   39   590]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.997     0.304     0.465     42572\n",
      "           1      0.020     0.938     0.038       629\n",
      "\n",
      "    accuracy                          0.313     43201\n",
      "   macro avg      0.508     0.621     0.252     43201\n",
      "weighted avg      0.983     0.313     0.459     43201\n",
      "\n",
      "\n",
      "=== Final Threshold Evaluation (p=40) ===\n",
      "threshold: 6.202758231665939e-05\n",
      "Confusion Matrix:\n",
      "[[17223 25349]\n",
      " [   57   572]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.997     0.405     0.576     42572\n",
      "           1      0.022     0.909     0.043       629\n",
      "\n",
      "    accuracy                          0.412     43201\n",
      "   macro avg      0.509     0.657     0.309     43201\n",
      "weighted avg      0.983     0.412     0.568     43201\n",
      "\n",
      "\n",
      "=== Final Threshold Evaluation (p=50) ===\n",
      "threshold: 7.695115345995873e-05\n",
      "Confusion Matrix:\n",
      "[[21518 21054]\n",
      " [   82   547]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.505     0.671     42572\n",
      "           1      0.025     0.870     0.049       629\n",
      "\n",
      "    accuracy                          0.511     43201\n",
      "   macro avg      0.511     0.688     0.360     43201\n",
      "weighted avg      0.982     0.511     0.662     43201\n",
      "\n",
      "\n",
      "=== Final Threshold Evaluation (p=60) ===\n",
      "threshold: 9.597399912308902e-05\n",
      "Confusion Matrix:\n",
      "[[25811 16761]\n",
      " [  109   520]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.606     0.754     42572\n",
      "           1      0.030     0.827     0.058       629\n",
      "\n",
      "    accuracy                          0.609     43201\n",
      "   macro avg      0.513     0.716     0.406     43201\n",
      "weighted avg      0.982     0.609     0.744     43201\n",
      "\n",
      "\n",
      "=== Final Threshold Evaluation (p=70) ===\n",
      "threshold: 0.00011918123345822095\n",
      "Confusion Matrix:\n",
      "[[30112 12460]\n",
      " [  128   501]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.707     0.827     42572\n",
      "           1      0.039     0.797     0.074       629\n",
      "\n",
      "    accuracy                          0.709     43201\n",
      "   macro avg      0.517     0.752     0.450     43201\n",
      "weighted avg      0.982     0.709     0.816     43201\n",
      "\n",
      "\n",
      "=== Final Threshold Evaluation (p=80) ===\n",
      "threshold: 0.00015056467964313924\n",
      "Confusion Matrix:\n",
      "[[34411  8161]\n",
      " [  149   480]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.808     0.892     42572\n",
      "           1      0.056     0.763     0.104       629\n",
      "\n",
      "    accuracy                          0.808     43201\n",
      "   macro avg      0.526     0.786     0.498     43201\n",
      "weighted avg      0.982     0.808     0.881     43201\n",
      "\n",
      "\n",
      "=== Final Threshold Evaluation (p=90) ===\n",
      "threshold: 0.00020388943084981292\n",
      "Confusion Matrix:\n",
      "[[38706  3866]\n",
      " [  174   455]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.909     0.950     42572\n",
      "           1      0.105     0.723     0.184       629\n",
      "\n",
      "    accuracy                          0.906     43201\n",
      "   macro avg      0.550     0.816     0.567     43201\n",
      "weighted avg      0.983     0.906     0.939     43201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,100,10):\n",
    "    best_p=i\n",
    "    thr_best = np.percentile(recon_error, best_p)\n",
    "    y_pred_final = (recon_error >= thr_best).astype(int)\n",
    "\n",
    "    print(\"\\n=== Final Threshold Evaluation (p=%d) ===\" % best_p)\n",
    "    print(\"threshold:\", thr_best)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred_final))\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred_final, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999cf42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
